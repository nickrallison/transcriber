use crate::{FileCategory, FileType, StringFile};
use crate::transcription::audio::transcribe_audio;
use crate::transcription::html::transcribe_html;
use crate::transcription::pdf::transcribe_pdf;
use crate::transcription::srt::transcribe_srt;
use crate::transcription::text::transcribe_text;
use crate::transcription::video::transcribe_video;

mod audio;
mod video;
mod html;
mod pdf;
mod srt;
mod text;

pub fn transcribe_file(file: FileType) -> Result<StringFile, crate::error::Error> {
    match file.category() {
        FileCategory::Audio => transcribe_audio(file),
        FileCategory::Video => transcribe_video(file),
        FileCategory::Html => transcribe_html(file),
        FileCategory::Pdf => transcribe_pdf(file),
        FileCategory::Text => transcribe_text(file),
        FileCategory::Srt => transcribe_srt(file),
    }
}

fn read_string_file(file_type: FileType) -> Result<String, crate::error::Error> {
    match file_type {
        FileType::StringFile(string_file) => Ok(string_file.contents),
        FileType::PathFile(path_file) => Ok(std::fs::read_to_string(path_file.path)?),
    }
}

#[cfg(test)]
mod transcription_test {
    use rstest::rstest;
    use crate::{FileType, StringFile};
    use crate::transcription::transcribe_file;

    #[rstest]
    #[case("[{\"StringFile\":{\"file_name\":{\"Windows\":[84,104,101,32,65,110,97,116,111,109,121,32,111,102,32,97,32,77,111,100,101,114,110,32,67,80,85,32,67,97,99,104,101,32,72,105,101,114,97,114,99,104,121,46,101,110]},\"contents\":\"WEBVTT\\nKind: captions\\nLanguage: en\\n\\n00:00:00.240 --> 00:00:02.389 align:start position:0%\\n \\ndid<00:00:00.399><c> you</c><00:00:00.560><c> know</c><00:00:00.919><c> that</c><00:00:01.199><c> accessing</c><00:00:01.599><c> main</c><00:00:01.880><c> memory</c>\\n\\n00:00:02.389 --> 00:00:02.399 align:start position:0%\\ndid you know that accessing main memory\\n \\n\\n00:00:02.399 --> 00:00:04.590 align:start position:0%\\ndid you know that accessing main memory\\ncan<00:00:02.560><c> take</c><00:00:02.800><c> hundreds</c><00:00:03.199><c> of</c><00:00:03.360><c> CPU</c>\\n\\n00:00:04.590 --> 00:00:04.600 align:start position:0%\\ncan take hundreds of CPU\\n \\n\\n00:00:04.600 --> 00:00:07.230 align:start position:0%\\ncan take hundreds of CPU\\nCycles<00:00:05.600><c> the</c><00:00:05.759><c> processor</c><00:00:06.240><c> operates</c><00:00:06.680><c> at</c><00:00:06.839><c> a</c><00:00:07.000><c> very</c>\\n\\n00:00:07.230 --> 00:00:07.240 align:start position:0%\\nCycles the processor operates at a very\\n \\n\\n00:00:07.240 --> 00:00:09.190 align:start position:0%\\nCycles the processor operates at a very\\nhigh<00:00:07.480><c> speed</c><00:00:08.160><c> but</c><00:00:08.360><c> every</c><00:00:08.559><c> time</c><00:00:08.719><c> it</c><00:00:08.840><c> needs</c><00:00:09.040><c> to</c>\\n\\n00:00:09.190 --> 00:00:09.200 align:start position:0%\\nhigh speed but every time it needs to\\n \\n\\n00:00:09.200 --> 00:00:11.509 align:start position:0%\\nhigh speed but every time it needs to\\nfetch<00:00:09.519><c> data</c><00:00:09.719><c> for</c><00:00:09.920><c> main</c><00:00:10.200><c> memory</c><00:00:10.840><c> it's</c><00:00:11.040><c> forced</c>\\n\\n00:00:11.509 --> 00:00:11.519 align:start position:0%\\nfetch data for main memory it's forced\\n \\n\\n00:00:11.519 --> 00:00:13.589 align:start position:0%\\nfetch data for main memory it's forced\\nto<00:00:11.719><c> wait</c><00:00:11.920><c> until</c><00:00:12.200><c> the</c><00:00:12.400><c> requested</c><00:00:12.880><c> data</c><00:00:13.120><c> is</c>\\n\\n00:00:13.589 --> 00:00:13.599 align:start position:0%\\nto wait until the requested data is\\n \\n\\n00:00:13.599 --> 00:00:15.990 align:start position:0%\\nto wait until the requested data is\\nretrieved<00:00:14.599><c> this</c><00:00:14.799><c> huge</c><00:00:15.120><c> delay</c><00:00:15.559><c> is</c><00:00:15.759><c> why</c>\\n\\n00:00:15.990 --> 00:00:16.000 align:start position:0%\\nretrieved this huge delay is why\\n \\n\\n00:00:16.000 --> 00:00:18.070 align:start position:0%\\nretrieved this huge delay is why\\ncomputers<00:00:16.440><c> have</c><00:00:16.640><c> caches</c><00:00:17.279><c> to</c><00:00:17.439><c> keep</c><00:00:17.680><c> the</c><00:00:17.840><c> data</c>\\n\\n00:00:18.070 --> 00:00:18.080 align:start position:0%\\ncomputers have caches to keep the data\\n \\n\\n00:00:18.080 --> 00:00:20.429 align:start position:0%\\ncomputers have caches to keep the data\\nthe<00:00:18.199><c> CPU</c><00:00:18.520><c> needs</c><00:00:18.840><c> closer</c><00:00:19.439><c> and</c><00:00:19.600><c> minimize</c><00:00:20.160><c> those</c>\\n\\n00:00:20.429 --> 00:00:20.439 align:start position:0%\\nthe CPU needs closer and minimize those\\n \\n\\n00:00:20.439 --> 00:00:22.990 align:start position:0%\\nthe CPU needs closer and minimize those\\ncostly\\n\\n00:00:22.990 --> 00:00:23.000 align:start position:0%\\n \\n \\n\\n00:00:23.000 --> 00:00:25.550 align:start position:0%\\n \\ninterruptions<00:00:24.000><c> modern</c><00:00:24.320><c> CPUs</c><00:00:24.960><c> feature</c><00:00:25.359><c> a</c>\\n\\n00:00:25.550 --> 00:00:25.560 align:start position:0%\\ninterruptions modern CPUs feature a\\n \\n\\n00:00:25.560 --> 00:00:27.710 align:start position:0%\\ninterruptions modern CPUs feature a\\nhierarchial<00:00:26.279><c> cache</c><00:00:26.560><c> system</c><00:00:27.119><c> where</c><00:00:27.320><c> the</c><00:00:27.439><c> cache</c>\\n\\n00:00:27.710 --> 00:00:27.720 align:start position:0%\\nhierarchial cache system where the cache\\n \\n\\n00:00:27.720 --> 00:00:29.349 align:start position:0%\\nhierarchial cache system where the cache\\nclosest<00:00:28.080><c> to</c><00:00:28.199><c> the</c><00:00:28.400><c> processor</c><00:00:28.800><c> core</c><00:00:29.080><c> is</c><00:00:29.240><c> the</c>\\n\\n00:00:29.349 --> 00:00:29.359 align:start position:0%\\nclosest to the processor core is the\\n \\n\\n00:00:29.359 --> 00:00:31.589 align:start position:0%\\nclosest to the processor core is the\\nsmallest<00:00:29.720><c> in</c><00:00:30.080><c> fastest</c><00:00:30.800><c> while</c><00:00:31.000><c> the</c><00:00:31.080><c> furthest</c>\\n\\n00:00:31.589 --> 00:00:31.599 align:start position:0%\\nsmallest in fastest while the furthest\\n \\n\\n00:00:31.599 --> 00:00:33.790 align:start position:0%\\nsmallest in fastest while the furthest\\ncache<00:00:32.079><c> is</c><00:00:32.239><c> the</c><00:00:32.399><c> largest</c><00:00:33.000><c> but</c>\\n\\n00:00:33.790 --> 00:00:33.800 align:start position:0%\\ncache is the largest but\\n \\n\\n00:00:33.800 --> 00:00:36.389 align:start position:0%\\ncache is the largest but\\nslowest<00:00:34.800><c> large</c><00:00:35.120><c> caches</c><00:00:35.480><c> are</c><00:00:35.640><c> inherently</c><00:00:36.120><c> more</c>\\n\\n00:00:36.389 --> 00:00:36.399 align:start position:0%\\nslowest large caches are inherently more\\n \\n\\n00:00:36.399 --> 00:00:38.270 align:start position:0%\\nslowest large caches are inherently more\\ncomplex<00:00:37.040><c> which</c><00:00:37.239><c> increases</c><00:00:37.680><c> their</c><00:00:37.960><c> access</c>\\n\\n00:00:38.270 --> 00:00:38.280 align:start position:0%\\ncomplex which increases their access\\n \\n\\n00:00:38.280 --> 00:00:40.430 align:start position:0%\\ncomplex which increases their access\\ntimes<00:00:38.840><c> so</c><00:00:39.040><c> to</c><00:00:39.200><c> maximize</c><00:00:39.719><c> performance</c><00:00:40.239><c> while</c>\\n\\n00:00:40.430 --> 00:00:40.440 align:start position:0%\\ntimes so to maximize performance while\\n \\n\\n00:00:40.440 --> 00:00:42.430 align:start position:0%\\ntimes so to maximize performance while\\nreducing<00:00:40.840><c> latency</c><00:00:41.360><c> and</c><00:00:41.559><c> cost</c><00:00:42.079><c> the</c><00:00:42.200><c> first</c>\\n\\n00:00:42.430 --> 00:00:42.440 align:start position:0%\\nreducing latency and cost the first\\n \\n\\n00:00:42.440 --> 00:00:44.869 align:start position:0%\\nreducing latency and cost the first\\nlevel<00:00:42.680><c> of</c><00:00:42.879><c> cache</c><00:00:43.160><c> known</c><00:00:43.399><c> as</c><00:00:43.559><c> L1</c><00:00:44.200><c> is</c><00:00:44.399><c> designed</c>\\n\\n00:00:44.869 --> 00:00:44.879 align:start position:0%\\nlevel of cache known as L1 is designed\\n \\n\\n00:00:44.879 --> 00:00:46.790 align:start position:0%\\nlevel of cache known as L1 is designed\\nto<00:00:45.000><c> be</c><00:00:45.200><c> very</c><00:00:45.399><c> small</c><00:00:45.800><c> to</c><00:00:46.039><c> match</c><00:00:46.280><c> the</c><00:00:46.399><c> speed</c><00:00:46.680><c> of</c>\\n\\n00:00:46.790 --> 00:00:46.800 align:start position:0%\\nto be very small to match the speed of\\n \\n\\n00:00:46.800 --> 00:00:47.590 align:start position:0%\\nto be very small to match the speed of\\nthe\\n\\n00:00:47.590 --> 00:00:47.600 align:start position:0%\\nthe\\n \\n\\n00:00:47.600 --> 00:00:50.110 align:start position:0%\\nthe\\nprocessor<00:00:48.600><c> L1</c><00:00:49.120><c> caches</c><00:00:49.480><c> are</c><00:00:49.680><c> typically</c>\\n\\n00:00:50.110 --> 00:00:50.120 align:start position:0%\\nprocessor L1 caches are typically\\n \\n\\n00:00:50.120 --> 00:00:52.630 align:start position:0%\\nprocessor L1 caches are typically\\ndivided<00:00:50.520><c> into</c><00:00:50.760><c> two</c><00:00:51.000><c> separate</c><00:00:51.399><c> components</c><00:00:52.359><c> one</c>\\n\\n00:00:52.630 --> 00:00:52.640 align:start position:0%\\ndivided into two separate components one\\n \\n\\n00:00:52.640 --> 00:00:54.630 align:start position:0%\\ndivided into two separate components one\\noptimized<00:00:53.120><c> for</c><00:00:53.320><c> data</c><00:00:53.520><c> fetching</c><00:00:54.160><c> and</c><00:00:54.320><c> another</c>\\n\\n00:00:54.630 --> 00:00:54.640 align:start position:0%\\noptimized for data fetching and another\\n \\n\\n00:00:54.640 --> 00:00:57.630 align:start position:0%\\noptimized for data fetching and another\\nfor<00:00:54.800><c> storing</c><00:00:55.760><c> instructions</c><00:00:56.760><c> at</c><00:00:56.960><c> this</c><00:00:57.160><c> point</c>\\n\\n00:00:57.630 --> 00:00:57.640 align:start position:0%\\nfor storing instructions at this point\\n \\n\\n00:00:57.640 --> 00:00:59.470 align:start position:0%\\nfor storing instructions at this point\\nthe<00:00:57.800><c> size</c><00:00:58.000><c> of</c><00:00:58.120><c> the</c><00:00:58.280><c> cache</c><00:00:58.600><c> becomes</c><00:00:58.879><c> a</c><00:00:59.000><c> limiting</c>\\n\\n00:00:59.470 --> 00:00:59.480 align:start position:0%\\nthe size of the cache becomes a limiting\\n \\n\\n00:00:59.480 --> 00:01:02.069 align:start position:0%\\nthe size of the cache becomes a limiting\\nfactor<00:01:00.239><c> so</c><00:01:00.440><c> to</c><00:01:00.600><c> solve</c><00:01:01.000><c> this</c><00:01:01.399><c> many</c><00:01:01.640><c> CPU</c>\\n\\n00:01:02.069 --> 00:01:02.079 align:start position:0%\\nfactor so to solve this many CPU\\n \\n\\n00:01:02.079 --> 00:01:04.070 align:start position:0%\\nfactor so to solve this many CPU\\narchitectures<00:01:02.760><c> incorporate</c><00:01:03.359><c> an</c><00:01:03.559><c> additional</c>\\n\\n00:01:04.070 --> 00:01:04.080 align:start position:0%\\narchitectures incorporate an additional\\n \\n\\n00:01:04.080 --> 00:01:06.429 align:start position:0%\\narchitectures incorporate an additional\\ncache<00:01:04.519><c> that</c><00:01:04.640><c> is</c><00:01:04.799><c> larger</c><00:01:05.239><c> in</c><00:01:05.479><c> size</c><00:01:06.000><c> but</c><00:01:06.159><c> works</c>\\n\\n00:01:06.429 --> 00:01:06.439 align:start position:0%\\ncache that is larger in size but works\\n \\n\\n00:01:06.439 --> 00:01:09.149 align:start position:0%\\ncache that is larger in size but works\\nat<00:01:06.600><c> lower</c><00:01:06.920><c> speeds</c><00:01:07.720><c> this</c><00:01:07.880><c> is</c><00:01:08.080><c> known</c><00:01:08.280><c> as</c><00:01:08.400><c> L2</c>\\n\\n00:01:09.149 --> 00:01:09.159 align:start position:0%\\nat lower speeds this is known as L2\\n \\n\\n00:01:09.159 --> 00:01:12.070 align:start position:0%\\nat lower speeds this is known as L2\\ncache<00:01:10.159><c> the</c><00:01:10.280><c> L2</c><00:01:10.720><c> cache</c><00:01:10.920><c> is</c><00:01:11.040><c> usually</c><00:01:11.320><c> a</c><00:01:11.479><c> unified</c>\\n\\n00:01:12.070 --> 00:01:12.080 align:start position:0%\\ncache the L2 cache is usually a unified\\n \\n\\n00:01:12.080 --> 00:01:14.310 align:start position:0%\\ncache the L2 cache is usually a unified\\ncache<00:01:12.600><c> which</c><00:01:12.759><c> means</c><00:01:13.000><c> it</c><00:01:13.159><c> can</c><00:01:13.280><c> store</c><00:01:13.640><c> both</c><00:01:13.960><c> data</c>\\n\\n00:01:14.310 --> 00:01:14.320 align:start position:0%\\ncache which means it can store both data\\n \\n\\n00:01:14.320 --> 00:01:16.950 align:start position:0%\\ncache which means it can store both data\\nand<00:01:14.960><c> instructions</c><00:01:15.960><c> it</c><00:01:16.119><c> is</c><00:01:16.280><c> dedicated</c><00:01:16.680><c> to</c><00:01:16.799><c> a</c>\\n\\n00:01:16.950 --> 00:01:16.960 align:start position:0%\\nand instructions it is dedicated to a\\n \\n\\n00:01:16.960 --> 00:01:19.070 align:start position:0%\\nand instructions it is dedicated to a\\nsingle<00:01:17.320><c> processor</c><00:01:17.799><c> core</c><00:01:18.280><c> and</c><00:01:18.439><c> can</c><00:01:18.640><c> directly</c>\\n\\n00:01:19.070 --> 00:01:19.080 align:start position:0%\\nsingle processor core and can directly\\n \\n\\n00:01:19.080 --> 00:01:21.789 align:start position:0%\\nsingle processor core and can directly\\ncommunicate<00:01:19.600><c> with</c><00:01:19.759><c> the</c><00:01:19.880><c> L1</c><00:01:20.400><c> caches</c><00:01:21.400><c> but</c><00:01:21.560><c> most</c>\\n\\n00:01:21.789 --> 00:01:21.799 align:start position:0%\\ncommunicate with the L1 caches but most\\n \\n\\n00:01:21.799 --> 00:01:24.030 align:start position:0%\\ncommunicate with the L1 caches but most\\nmodern<00:01:22.200><c> systems</c><00:01:22.520><c> are</c><00:01:22.720><c> multi-core</c><00:01:23.439><c> systems</c>\\n\\n00:01:24.030 --> 00:01:24.040 align:start position:0%\\nmodern systems are multi-core systems\\n \\n\\n00:01:24.040 --> 00:01:25.789 align:start position:0%\\nmodern systems are multi-core systems\\nand<00:01:24.200><c> need</c><00:01:24.360><c> a</c><00:01:24.520><c> fast</c><00:01:24.840><c> way</c><00:01:25.040><c> to</c><00:01:25.200><c> share</c><00:01:25.520><c> data</c>\\n\\n00:01:25.789 --> 00:01:25.799 align:start position:0%\\nand need a fast way to share data\\n \\n\\n00:01:25.799 --> 00:01:28.149 align:start position:0%\\nand need a fast way to share data\\nbetween<00:01:26.159><c> them</c><00:01:26.960><c> that's</c><00:01:27.119><c> why</c><00:01:27.280><c> CPUs</c><00:01:27.799><c> usually</c>\\n\\n00:01:28.149 --> 00:01:28.159 align:start position:0%\\nbetween them that's why CPUs usually\\n \\n\\n00:01:28.159 --> 00:01:31.149 align:start position:0%\\nbetween them that's why CPUs usually\\nhave<00:01:28.360><c> another</c><00:01:28.799><c> cache</c><00:01:29.400><c> L3</c>\\n\\n00:01:31.149 --> 00:01:31.159 align:start position:0%\\nhave another cache L3\\n \\n\\n00:01:31.159 --> 00:01:34.310 align:start position:0%\\nhave another cache L3\\nthis<00:01:31.360><c> cache</c><00:01:31.600><c> is</c><00:01:31.759><c> larger</c><00:01:32.280><c> but</c><00:01:32.399><c> slower</c><00:01:32.799><c> than</c><00:01:33.320><c> L2</c>\\n\\n00:01:34.310 --> 00:01:34.320 align:start position:0%\\nthis cache is larger but slower than L2\\n \\n\\n00:01:34.320 --> 00:01:36.990 align:start position:0%\\nthis cache is larger but slower than L2\\nit<00:01:34.479><c> serves</c><00:01:34.840><c> two</c><00:01:35.040><c> main</c><00:01:35.479><c> purposes</c><00:01:36.479><c> it</c><00:01:36.640><c> allows</c>\\n\\n00:01:36.990 --> 00:01:37.000 align:start position:0%\\nit serves two main purposes it allows\\n \\n\\n00:01:37.000 --> 00:01:38.950 align:start position:0%\\nit serves two main purposes it allows\\ndata<00:01:37.200><c> sharing</c><00:01:37.560><c> between</c><00:01:38.000><c> processor</c><00:01:38.399><c> cores</c>\\n\\n00:01:38.950 --> 00:01:38.960 align:start position:0%\\ndata sharing between processor cores\\n \\n\\n00:01:38.960 --> 00:01:41.550 align:start position:0%\\ndata sharing between processor cores\\nwithout<00:01:39.360><c> accessing</c><00:01:39.759><c> main</c><00:01:40.000><c> memory</c><00:01:40.840><c> and</c><00:01:41.399><c> it</c>\\n\\n00:01:41.550 --> 00:01:41.560 align:start position:0%\\nwithout accessing main memory and it\\n \\n\\n00:01:41.560 --> 00:01:43.149 align:start position:0%\\nwithout accessing main memory and it\\nprovides<00:01:41.920><c> an</c><00:01:42.079><c> additional</c><00:01:42.479><c> layer</c><00:01:42.880><c> in</c><00:01:43.000><c> the</c>\\n\\n00:01:43.149 --> 00:01:43.159 align:start position:0%\\nprovides an additional layer in the\\n \\n\\n00:01:43.159 --> 00:01:44.109 align:start position:0%\\nprovides an additional layer in the\\nmemory\\n\\n00:01:44.109 --> 00:01:44.119 align:start position:0%\\nmemory\\n \\n\\n00:01:44.119 --> 00:01:46.990 align:start position:0%\\nmemory\\nhierarchy<00:01:45.119><c> when</c><00:01:45.320><c> both</c><00:01:45.560><c> L1</c><00:01:46.000><c> and</c><00:01:46.119><c> L2</c><00:01:46.560><c> caches</c>\\n\\n00:01:46.990 --> 00:01:47.000 align:start position:0%\\nhierarchy when both L1 and L2 caches\\n \\n\\n00:01:47.000 --> 00:01:49.310 align:start position:0%\\nhierarchy when both L1 and L2 caches\\nmiss<00:01:47.560><c> the</c><00:01:47.680><c> L3</c><00:01:48.159><c> cache</c><00:01:48.439><c> is</c><00:01:48.600><c> checked</c><00:01:49.079><c> before</c>\\n\\n00:01:49.310 --> 00:01:49.320 align:start position:0%\\nmiss the L3 cache is checked before\\n \\n\\n00:01:49.320 --> 00:01:51.510 align:start position:0%\\nmiss the L3 cache is checked before\\nresorting<00:01:49.759><c> to</c><00:01:49.920><c> main</c><00:01:50.159><c> memory</c><00:01:51.159><c> some</c>\\n\\n00:01:51.510 --> 00:01:51.520 align:start position:0%\\nresorting to main memory some\\n \\n\\n00:01:51.520 --> 00:01:54.429 align:start position:0%\\nresorting to main memory some\\nspecialized<00:01:52.200><c> systems</c><00:01:52.880><c> add</c><00:01:53.159><c> an</c><00:01:53.360><c> L4</c><00:01:53.920><c> cache</c><00:01:54.240><c> on</c>\\n\\n00:01:54.429 --> 00:01:54.439 align:start position:0%\\nspecialized systems add an L4 cache on\\n \\n\\n00:01:54.439 --> 00:01:56.830 align:start position:0%\\nspecialized systems add an L4 cache on\\ntop<00:01:54.640><c> of</c><00:01:54.759><c> the</c><00:01:54.880><c> usual</c><00:01:55.200><c> L1</c><00:01:55.719><c> 2</c><00:01:55.920><c> and</c><00:01:56.119><c> three</c><00:01:56.360><c> caches</c>\\n\\n00:01:56.830 --> 00:01:56.840 align:start position:0%\\ntop of the usual L1 2 and three caches\\n \\n\\n00:01:56.840 --> 00:02:01.789 align:start position:0%\\ntop of the usual L1 2 and three caches\\nto<00:01:57.000><c> boost</c><00:01:57.320><c> performance</c><00:01:57.840><c> even</c><00:01:58.119><c> more</c>\\n\\n00:02:01.789 --> 00:02:01.799 align:start position:0%\\n \\n \\n\\n00:02:01.799 --> 00:02:03.550 align:start position:0%\\n \\nthe<00:02:01.920><c> L1</c><00:02:02.360><c> cach</c><00:02:02.600><c> is</c><00:02:02.719><c> the</c><00:02:02.880><c> smallest</c><00:02:03.280><c> in</c><00:02:03.399><c> the</c>\\n\\n00:02:03.550 --> 00:02:03.560 align:start position:0%\\nthe L1 cach is the smallest in the\\n \\n\\n00:02:03.560 --> 00:02:05.830 align:start position:0%\\nthe L1 cach is the smallest in the\\nhierarchy<00:02:04.280><c> typically</c><00:02:04.719><c> ranging</c><00:02:05.119><c> from</c><00:02:05.360><c> 16</c>\\n\\n00:02:05.830 --> 00:02:05.840 align:start position:0%\\nhierarchy typically ranging from 16\\n \\n\\n00:02:05.840 --> 00:02:09.869 align:start position:0%\\nhierarchy typically ranging from 16\\nkiloby<00:02:06.439><c> to</c><00:02:06.680><c> 128</c><00:02:07.640><c> kilobytes</c><00:02:08.200><c> per</c><00:02:08.599><c> core</c><00:02:09.599><c> it</c><00:02:09.759><c> has</c>\\n\\n00:02:09.869 --> 00:02:09.879 align:start position:0%\\nkiloby to 128 kilobytes per core it has\\n \\n\\n00:02:09.879 --> 00:02:11.830 align:start position:0%\\nkiloby to 128 kilobytes per core it has\\nan<00:02:10.039><c> associativity</c><00:02:10.759><c> of</c><00:02:10.959><c> between</c><00:02:11.319><c> two</c><00:02:11.599><c> and</c>\\n\\n00:02:11.830 --> 00:02:11.840 align:start position:0%\\nan associativity of between two and\\n \\n\\n00:02:11.840 --> 00:02:14.990 align:start position:0%\\nan associativity of between two and\\neight<00:02:12.560><c> ways</c><00:02:13.560><c> it</c><00:02:13.680><c> is</c><00:02:13.879><c> the</c><00:02:14.080><c> fastest</c><00:02:14.519><c> among</c><00:02:14.760><c> all</c>\\n\\n00:02:14.990 --> 00:02:15.000 align:start position:0%\\neight ways it is the fastest among all\\n \\n\\n00:02:15.000 --> 00:02:17.309 align:start position:0%\\neight ways it is the fastest among all\\ncaches<00:02:15.640><c> with</c><00:02:15.800><c> a</c><00:02:15.959><c> latency</c><00:02:16.560><c> in</c><00:02:16.680><c> the</c><00:02:16.800><c> range</c><00:02:17.040><c> of</c><00:02:17.200><c> a</c>\\n\\n00:02:17.309 --> 00:02:17.319 align:start position:0%\\ncaches with a latency in the range of a\\n \\n\\n00:02:17.319 --> 00:02:18.750 align:start position:0%\\ncaches with a latency in the range of a\\nfew<00:02:17.519><c> CPU</c>\\n\\n00:02:18.750 --> 00:02:18.760 align:start position:0%\\nfew CPU\\n \\n\\n00:02:18.760 --> 00:02:21.670 align:start position:0%\\nfew CPU\\nCycles<00:02:19.760><c> L2</c><00:02:20.239><c> caches</c><00:02:20.640><c> are</c><00:02:20.879><c> slightly</c><00:02:21.280><c> larger</c>\\n\\n00:02:21.670 --> 00:02:21.680 align:start position:0%\\nCycles L2 caches are slightly larger\\n \\n\\n00:02:21.680 --> 00:02:25.430 align:start position:0%\\nCycles L2 caches are slightly larger\\nthan<00:02:21.840><c> L1</c><00:02:22.480><c> ranging</c><00:02:22.920><c> from</c><00:02:23.440><c> 256</c><00:02:24.440><c> kiloby</c><00:02:25.040><c> to</c><00:02:25.200><c> 2</c>\\n\\n00:02:25.430 --> 00:02:25.440 align:start position:0%\\nthan L1 ranging from 256 kiloby to 2\\n \\n\\n00:02:25.440 --> 00:02:27.630 align:start position:0%\\nthan L1 ranging from 256 kiloby to 2\\nmegabytes<00:02:25.959><c> per</c><00:02:26.120><c> core</c><00:02:26.640><c> with</c><00:02:26.760><c> older</c><00:02:27.120><c> machines</c>\\n\\n00:02:27.630 --> 00:02:27.640 align:start position:0%\\nmegabytes per core with older machines\\n \\n\\n00:02:27.640 --> 00:02:30.550 align:start position:0%\\nmegabytes per core with older machines\\nhaving<00:02:27.920><c> up</c><00:02:28.040><c> to</c><00:02:28.239><c> several</c><00:02:28.599><c> megabytes</c><00:02:29.120><c> per</c><00:02:29.280><c> core</c>\\n\\n00:02:30.550 --> 00:02:30.560 align:start position:0%\\nhaving up to several megabytes per core\\n \\n\\n00:02:30.560 --> 00:02:33.509 align:start position:0%\\nhaving up to several megabytes per core\\nin<00:02:30.720><c> terms</c><00:02:30.959><c> of</c><00:02:31.280><c> associativity</c><00:02:32.280><c> L2</c><00:02:33.000><c> has</c><00:02:33.200><c> between</c>\\n\\n00:02:33.509 --> 00:02:33.519 align:start position:0%\\nin terms of associativity L2 has between\\n \\n\\n00:02:33.519 --> 00:02:36.430 align:start position:0%\\nin terms of associativity L2 has between\\nfour<00:02:33.760><c> and</c><00:02:33.959><c> 16</c><00:02:34.400><c> ways</c><00:02:35.080><c> and</c><00:02:35.239><c> a</c><00:02:35.400><c> latency</c><00:02:35.879><c> of</c><00:02:36.000><c> 4</c><00:02:36.280><c> to</c>\\n\\n00:02:36.430 --> 00:02:36.440 align:start position:0%\\nfour and 16 ways and a latency of 4 to\\n \\n\\n00:02:36.440 --> 00:02:37.790 align:start position:0%\\nfour and 16 ways and a latency of 4 to\\n10<00:02:36.640><c> CPU</c>\\n\\n00:02:37.790 --> 00:02:37.800 align:start position:0%\\n10 CPU\\n \\n\\n00:02:37.800 --> 00:02:40.750 align:start position:0%\\n10 CPU\\nCycles<00:02:38.800><c> L3</c><00:02:39.319><c> caches</c><00:02:39.720><c> are</c><00:02:39.879><c> the</c><00:02:40.040><c> largest</c><00:02:40.440><c> in</c><00:02:40.599><c> the</c>\\n\\n00:02:40.750 --> 00:02:40.760 align:start position:0%\\nCycles L3 caches are the largest in the\\n \\n\\n00:02:40.760 --> 00:02:42.949 align:start position:0%\\nCycles L3 caches are the largest in the\\nhierarchy<00:02:41.239><c> in</c><00:02:41.400><c> most</c><00:02:41.680><c> architectures</c><00:02:42.560><c> ranging</c>\\n\\n00:02:42.949 --> 00:02:42.959 align:start position:0%\\nhierarchy in most architectures ranging\\n \\n\\n00:02:42.959 --> 00:02:45.949 align:start position:0%\\nhierarchy in most architectures ranging\\nfrom<00:02:43.120><c> 2</c><00:02:43.360><c> mbes</c><00:02:43.879><c> to</c><00:02:44.080><c> 32</c><00:02:44.560><c> mbes</c><00:02:45.040><c> per</c><00:02:45.239><c> core</c><00:02:45.720><c> with</c>\\n\\n00:02:45.949 --> 00:02:45.959 align:start position:0%\\nfrom 2 mbes to 32 mbes per core with\\n \\n\\n00:02:45.959 --> 00:02:48.710 align:start position:0%\\nfrom 2 mbes to 32 mbes per core with\\nsome<00:02:46.200><c> apple</c><00:02:46.680><c> and</c><00:02:46.879><c> AMD</c><00:02:47.400><c> CPUs</c><00:02:48.080><c> having</c><00:02:48.360><c> more</c><00:02:48.560><c> than</c>\\n\\n00:02:48.710 --> 00:02:48.720 align:start position:0%\\nsome apple and AMD CPUs having more than\\n \\n\\n00:02:48.720 --> 00:02:52.350 align:start position:0%\\nsome apple and AMD CPUs having more than\\n32<00:02:49.200><c> MBT</c><00:02:49.680><c> per</c><00:02:50.000><c> core</c><00:02:51.000><c> L3</c><00:02:51.599><c> typically</c><00:02:52.040><c> has</c><00:02:52.159><c> an</c>\\n\\n00:02:52.350 --> 00:02:52.360 align:start position:0%\\n32 MBT per core L3 typically has an\\n \\n\\n00:02:52.360 --> 00:02:55.149 align:start position:0%\\n32 MBT per core L3 typically has an\\nassociativity<00:02:53.239><c> of</c><00:02:53.400><c> 16</c><00:02:53.920><c> ways</c><00:02:54.560><c> though</c><00:02:54.760><c> this</c><00:02:54.920><c> can</c>\\n\\n00:02:55.149 --> 00:02:55.159 align:start position:0%\\nassociativity of 16 ways though this can\\n \\n\\n00:02:55.159 --> 00:02:57.869 align:start position:0%\\nassociativity of 16 ways though this can\\nvary<00:02:55.440><c> between</c><00:02:55.760><c> system</c><00:02:56.560><c> architectures</c><00:02:57.560><c> it</c><00:02:57.720><c> has</c>\\n\\n00:02:57.869 --> 00:02:57.879 align:start position:0%\\nvary between system architectures it has\\n \\n\\n00:02:57.879 --> 00:03:00.070 align:start position:0%\\nvary between system architectures it has\\nthe<00:02:58.000><c> longest</c><00:02:58.360><c> latency</c><00:02:59.120><c> ranging</c><00:02:59.480><c> from</c><00:02:59.640><c> 10</c><00:02:59.840><c> 10</c>\\n\\n00:03:00.070 --> 00:03:00.080 align:start position:0%\\nthe longest latency ranging from 10 10\\n \\n\\n00:03:00.080 --> 00:03:01.750 align:start position:0%\\nthe longest latency ranging from 10 10\\nto<00:03:00.239><c> 40</c>\\n\\n00:03:01.750 --> 00:03:01.760 align:start position:0%\\nto 40\\n \\n\\n00:03:01.760 --> 00:03:04.229 align:start position:0%\\nto 40\\nCycles<00:03:02.760><c> cash</c><00:03:03.040><c> hierarchies</c><00:03:03.879><c> can</c><00:03:04.040><c> be</c>\\n\\n00:03:04.229 --> 00:03:04.239 align:start position:0%\\nCycles cash hierarchies can be\\n \\n\\n00:03:04.239 --> 00:03:06.589 align:start position:0%\\nCycles cash hierarchies can be\\ncategorized<00:03:04.959><c> by</c><00:03:05.120><c> their</c><00:03:05.319><c> inclusion</c><00:03:05.879><c> policies</c>\\n\\n00:03:06.589 --> 00:03:06.599 align:start position:0%\\ncategorized by their inclusion policies\\n \\n\\n00:03:06.599 --> 00:03:08.509 align:start position:0%\\ncategorized by their inclusion policies\\nwhich<00:03:06.840><c> decide</c><00:03:07.360><c> whether</c><00:03:07.560><c> a</c><00:03:07.799><c> data</c><00:03:08.000><c> block</c><00:03:08.360><c> is</c>\\n\\n00:03:08.509 --> 00:03:08.519 align:start position:0%\\nwhich decide whether a data block is\\n \\n\\n00:03:08.519 --> 00:03:10.750 align:start position:0%\\nwhich decide whether a data block is\\nstored<00:03:08.959><c> in</c><00:03:09.159><c> just</c><00:03:09.360><c> one</c><00:03:09.599><c> cach</c><00:03:09.879><c> level</c><00:03:10.400><c> copied</c>\\n\\n00:03:10.750 --> 00:03:10.760 align:start position:0%\\nstored in just one cach level copied\\n \\n\\n00:03:10.760 --> 00:03:12.910 align:start position:0%\\nstored in just one cach level copied\\nacross<00:03:11.080><c> multiple</c><00:03:11.519><c> levels</c><00:03:12.159><c> or</c><00:03:12.360><c> handled</c><00:03:12.720><c> in</c><00:03:12.840><c> a</c>\\n\\n00:03:12.910 --> 00:03:12.920 align:start position:0%\\nacross multiple levels or handled in a\\n \\n\\n00:03:12.920 --> 00:03:15.869 align:start position:0%\\nacross multiple levels or handled in a\\nmore<00:03:13.120><c> flexible</c>\\n\\n00:03:15.869 --> 00:03:15.879 align:start position:0%\\n \\n \\n\\n00:03:15.879 --> 00:03:18.430 align:start position:0%\\n \\nmanner<00:03:16.879><c> the</c><00:03:17.040><c> three</c><00:03:17.239><c> main</c><00:03:17.480><c> inclusion</c><00:03:17.959><c> policies</c>\\n\\n00:03:18.430 --> 00:03:18.440 align:start position:0%\\nmanner the three main inclusion policies\\n \\n\\n00:03:18.440 --> 00:03:21.070 align:start position:0%\\nmanner the three main inclusion policies\\nare<00:03:18.879><c> inclusive</c><00:03:19.879><c> exclusive</c><00:03:20.879><c> and</c>\\n\\n00:03:21.070 --> 00:03:21.080 align:start position:0%\\nare inclusive exclusive and\\n \\n\\n00:03:21.080 --> 00:03:23.990 align:start position:0%\\nare inclusive exclusive and\\nnon-inclusive<00:03:21.840><c> non-exclusive</c><00:03:22.760><c> or</c><00:03:23.000><c> nine</c><00:03:23.480><c> in</c>\\n\\n00:03:23.990 --> 00:03:24.000 align:start position:0%\\nnon-inclusive non-exclusive or nine in\\n \\n\\n00:03:24.000 --> 00:03:26.750 align:start position:0%\\nnon-inclusive non-exclusive or nine in\\nshort<00:03:25.000><c> in</c><00:03:25.120><c> the</c><00:03:25.239><c> inclusive</c><00:03:25.799><c> policy</c><00:03:26.519><c> data</c>\\n\\n00:03:26.750 --> 00:03:26.760 align:start position:0%\\nshort in the inclusive policy data\\n \\n\\n00:03:26.760 --> 00:03:28.670 align:start position:0%\\nshort in the inclusive policy data\\nstored<00:03:27.080><c> in</c><00:03:27.159><c> a</c><00:03:27.319><c> higher</c><00:03:27.599><c> level</c><00:03:27.920><c> cache</c><00:03:28.360><c> such</c><00:03:28.560><c> as</c>\\n\\n00:03:28.670 --> 00:03:28.680 align:start position:0%\\nstored in a higher level cache such as\\n \\n\\n00:03:28.680 --> 00:03:30.429 align:start position:0%\\nstored in a higher level cache such as\\nL1<00:03:29.280><c> which</c><00:03:29.400><c> is</c><00:03:29.519><c> close</c><00:03:29.760><c> closest</c><00:03:30.120><c> to</c><00:03:30.280><c> the</c>\\n\\n00:03:30.429 --> 00:03:30.439 align:start position:0%\\nL1 which is close closest to the\\n \\n\\n00:03:30.439 --> 00:03:32.550 align:start position:0%\\nL1 which is close closest to the\\nprocessor<00:03:30.879><c> core</c><00:03:31.319><c> is</c><00:03:31.519><c> also</c><00:03:31.720><c> stored</c><00:03:32.080><c> in</c><00:03:32.239><c> lower</c>\\n\\n00:03:32.550 --> 00:03:32.560 align:start position:0%\\nprocessor core is also stored in lower\\n \\n\\n00:03:32.560 --> 00:03:35.830 align:start position:0%\\nprocessor core is also stored in lower\\nlevel<00:03:32.840><c> caches</c><00:03:33.319><c> like</c><00:03:33.480><c> L2</c><00:03:34.040><c> and</c><00:03:34.239><c> possibly</c><00:03:34.640><c> L3</c><00:03:35.640><c> in</c>\\n\\n00:03:35.830 --> 00:03:35.840 align:start position:0%\\nlevel caches like L2 and possibly L3 in\\n \\n\\n00:03:35.840 --> 00:03:39.030 align:start position:0%\\nlevel caches like L2 and possibly L3 in\\nthis<00:03:36.080><c> case</c><00:03:36.640><c> you</c><00:03:36.760><c> could</c><00:03:36.959><c> say</c><00:03:37.159><c> that</c><00:03:37.319><c> L2</c><00:03:37.959><c> includes</c>\\n\\n00:03:39.030 --> 00:03:39.040 align:start position:0%\\nthis case you could say that L2 includes\\n \\n\\n00:03:39.040 --> 00:03:42.309 align:start position:0%\\nthis case you could say that L2 includes\\nL1<00:03:40.040><c> the</c><00:03:40.280><c> exclusive</c><00:03:40.879><c> policy</c><00:03:41.560><c> states</c><00:03:42.000><c> that</c><00:03:42.120><c> a</c>\\n\\n00:03:42.309 --> 00:03:42.319 align:start position:0%\\nL1 the exclusive policy states that a\\n \\n\\n00:03:42.319 --> 00:03:44.509 align:start position:0%\\nL1 the exclusive policy states that a\\ndata<00:03:42.560><c> block</c><00:03:43.040><c> can</c><00:03:43.239><c> only</c><00:03:43.599><c> exist</c><00:03:43.840><c> in</c><00:03:44.040><c> one</c><00:03:44.280><c> cach</c>\\n\\n00:03:44.509 --> 00:03:44.519 align:start position:0%\\ndata block can only exist in one cach\\n \\n\\n00:03:44.519 --> 00:03:47.589 align:start position:0%\\ndata block can only exist in one cach\\nlevel<00:03:44.799><c> at</c><00:03:44.920><c> a</c><00:03:45.120><c> time</c><00:03:46.040><c> if</c><00:03:46.159><c> it's</c><00:03:46.319><c> an</c><00:03:46.480><c> L1</c><00:03:47.159><c> it</c><00:03:47.319><c> won't</c>\\n\\n00:03:47.589 --> 00:03:47.599 align:start position:0%\\nlevel at a time if it's an L1 it won't\\n \\n\\n00:03:47.599 --> 00:03:50.990 align:start position:0%\\nlevel at a time if it's an L1 it won't\\nbe<00:03:47.760><c> in</c><00:03:47.920><c> L2</c><00:03:48.360><c> or</c><00:03:48.560><c> L3</c><00:03:49.200><c> and</c><00:03:49.400><c> vice</c><00:03:49.640><c> versa</c><00:03:50.599><c> in</c><00:03:50.799><c> this</c>\\n\\n00:03:50.990 --> 00:03:51.000 align:start position:0%\\nbe in L2 or L3 and vice versa in this\\n \\n\\n00:03:51.000 --> 00:03:53.990 align:start position:0%\\nbe in L2 or L3 and vice versa in this\\ninstance<00:03:51.640><c> L2</c><00:03:52.280><c> is</c><00:03:52.599><c> exclusive</c><00:03:53.120><c> of</c>\\n\\n00:03:53.990 --> 00:03:54.000 align:start position:0%\\ninstance L2 is exclusive of\\n \\n\\n00:03:54.000 --> 00:03:56.750 align:start position:0%\\ninstance L2 is exclusive of\\nL1<00:03:55.000><c> the</c><00:03:55.159><c> non-inclusive</c><00:03:55.920><c> non-exclusive</c>\\n\\n00:03:56.750 --> 00:03:56.760 align:start position:0%\\nL1 the non-inclusive non-exclusive\\n \\n\\n00:03:56.760 --> 00:03:59.550 align:start position:0%\\nL1 the non-inclusive non-exclusive\\npolicy<00:03:57.360><c> is</c><00:03:57.480><c> a</c><00:03:57.680><c> hybrid</c><00:03:58.079><c> of</c><00:03:58.200><c> the</c><00:03:58.360><c> previous</c><00:03:58.720><c> two</c>\\n\\n00:03:59.550 --> 00:03:59.560 align:start position:0%\\npolicy is a hybrid of the previous two\\n \\n\\n00:03:59.560 --> 00:04:01.270 align:start position:0%\\npolicy is a hybrid of the previous two\\nthe<00:03:59.760><c> there</c><00:03:59.840><c> is</c><00:03:59.959><c> no</c><00:04:00.120><c> strict</c><00:04:00.439><c> rule</c><00:04:00.720><c> for</c>\\n\\n00:04:01.270 --> 00:04:01.280 align:start position:0%\\nthe there is no strict rule for\\n \\n\\n00:04:01.280 --> 00:04:03.789 align:start position:0%\\nthe there is no strict rule for\\nduplication<00:04:02.280><c> data</c><00:04:02.640><c> may</c><00:04:02.879><c> or</c><00:04:03.079><c> may</c><00:04:03.239><c> not</c><00:04:03.480><c> exist</c>\\n\\n00:04:03.789 --> 00:04:03.799 align:start position:0%\\nduplication data may or may not exist\\n \\n\\n00:04:03.799 --> 00:04:05.830 align:start position:0%\\nduplication data may or may not exist\\nacross<00:04:04.120><c> multiple</c><00:04:04.560><c> cache</c><00:04:04.840><c> levels</c><00:04:05.439><c> depending</c>\\n\\n00:04:05.830 --> 00:04:05.840 align:start position:0%\\nacross multiple cache levels depending\\n \\n\\n00:04:05.840 --> 00:04:08.910 align:start position:0%\\nacross multiple cache levels depending\\non<00:04:06.000><c> the</c><00:04:06.159><c> systems</c><00:04:07.120><c> design</c><00:04:08.120><c> in</c><00:04:08.319><c> Real</c><00:04:08.599><c> World</c>\\n\\n00:04:08.910 --> 00:04:08.920 align:start position:0%\\non the systems design in Real World\\n \\n\\n00:04:08.920 --> 00:04:11.350 align:start position:0%\\non the systems design in Real World\\nSystems<00:04:09.680><c> CPU</c><00:04:10.159><c> cache</c><00:04:10.400><c> hierarchies</c><00:04:11.000><c> combine</c>\\n\\n00:04:11.350 --> 00:04:11.360 align:start position:0%\\nSystems CPU cache hierarchies combine\\n \\n\\n00:04:11.360 --> 00:04:14.229 align:start position:0%\\nSystems CPU cache hierarchies combine\\ninclusion<00:04:12.000><c> policies</c><00:04:13.000><c> for</c><00:04:13.200><c> example</c><00:04:13.840><c> Intel</c>\\n\\n00:04:14.229 --> 00:04:14.239 align:start position:0%\\ninclusion policies for example Intel\\n \\n\\n00:04:14.239 --> 00:04:16.590 align:start position:0%\\ninclusion policies for example Intel\\nprocessors<00:04:14.799><c> like</c><00:04:15.000><c> sandybridge</c><00:04:15.600><c> ivybridge</c>\\n\\n00:04:16.590 --> 00:04:16.600 align:start position:0%\\nprocessors like sandybridge ivybridge\\n \\n\\n00:04:16.600 --> 00:04:19.310 align:start position:0%\\nprocessors like sandybridge ivybridge\\nand<00:04:16.759><c> Skylake</c><00:04:17.560><c> have</c><00:04:17.720><c> an</c><00:04:17.880><c> inclusive</c><00:04:18.359><c> L3</c><00:04:18.840><c> cache</c>\\n\\n00:04:19.310 --> 00:04:19.320 align:start position:0%\\nand Skylake have an inclusive L3 cache\\n \\n\\n00:04:19.320 --> 00:04:21.510 align:start position:0%\\nand Skylake have an inclusive L3 cache\\nand<00:04:19.440><c> a</c><00:04:19.600><c> non-inclusive</c><00:04:20.320><c> non-exclusive</c><00:04:21.079><c> L2</c>\\n\\n00:04:21.510 --> 00:04:21.520 align:start position:0%\\nand a non-inclusive non-exclusive L2\\n \\n\\n00:04:21.520 --> 00:04:23.909 align:start position:0%\\nand a non-inclusive non-exclusive L2\\ncache<00:04:22.520><c> each</c><00:04:22.680><c> of</c><00:04:22.840><c> these</c><00:04:23.080><c> policies</c><00:04:23.520><c> has</c><00:04:23.680><c> its</c>\\n\\n00:04:23.909 --> 00:04:23.919 align:start position:0%\\ncache each of these policies has its\\n \\n\\n00:04:23.919 --> 00:04:25.749 align:start position:0%\\ncache each of these policies has its\\nbenefits<00:04:24.320><c> and</c><00:04:24.479><c> drawbacks</c><00:04:25.160><c> but</c><00:04:25.280><c> they</c><00:04:25.400><c> all</c><00:04:25.600><c> play</c>\\n\\n00:04:25.749 --> 00:04:25.759 align:start position:0%\\nbenefits and drawbacks but they all play\\n \\n\\n00:04:25.759 --> 00:04:27.629 align:start position:0%\\nbenefits and drawbacks but they all play\\na<00:04:25.880><c> role</c><00:04:26.080><c> in</c><00:04:26.240><c> how</c><00:04:26.479><c> data</c><00:04:26.720><c> is</c><00:04:26.840><c> retrieved</c><00:04:27.440><c> or</c>\\n\\n00:04:27.629 --> 00:04:27.639 align:start position:0%\\na role in how data is retrieved or\\n \\n\\n00:04:27.639 --> 00:04:29.909 align:start position:0%\\na role in how data is retrieved or\\nwritten<00:04:28.120><c> within</c><00:04:28.360><c> the</c><00:04:28.520><c> cash</c><00:04:28.759><c> hierarchy</c><00:04:29.759><c> let's</c>\\n\\n00:04:29.909 --> 00:04:29.919 align:start position:0%\\nwritten within the cash hierarchy let's\\n \\n\\n00:04:29.919 --> 00:04:32.550 align:start position:0%\\nwritten within the cash hierarchy let's\\nlook<00:04:30.080><c> at</c><00:04:30.199><c> an</c><00:04:30.840><c> example</c><00:04:31.840><c> let's</c><00:04:32.080><c> assume</c><00:04:32.320><c> we</c><00:04:32.440><c> have</c>\\n\\n00:04:32.550 --> 00:04:32.560 align:start position:0%\\nlook at an example let's assume we have\\n \\n\\n00:04:32.560 --> 00:04:34.710 align:start position:0%\\nlook at an example let's assume we have\\nan<00:04:32.720><c> inclusive</c><00:04:33.240><c> cache</c><00:04:33.520><c> hierarchy</c><00:04:34.160><c> with</c><00:04:34.320><c> three</c>\\n\\n00:04:34.710 --> 00:04:34.720 align:start position:0%\\nan inclusive cache hierarchy with three\\n \\n\\n00:04:34.720 --> 00:04:37.710 align:start position:0%\\nan inclusive cache hierarchy with three\\nlevels<00:04:35.720><c> a</c><00:04:35.880><c> read</c><00:04:36.199><c> request</c><00:04:36.759><c> will</c><00:04:36.960><c> always</c><00:04:37.280><c> start</c>\\n\\n00:04:37.710 --> 00:04:37.720 align:start position:0%\\nlevels a read request will always start\\n \\n\\n00:04:37.720 --> 00:04:40.550 align:start position:0%\\nlevels a read request will always start\\nat<00:04:37.840><c> the</c><00:04:37.960><c> highest</c><00:04:38.280><c> cache</c><00:04:38.520><c> level</c><00:04:39.240><c> L1</c><00:04:40.240><c> if</c><00:04:40.400><c> the</c>\\n\\n00:04:40.550 --> 00:04:40.560 align:start position:0%\\nat the highest cache level L1 if the\\n \\n\\n00:04:40.560 --> 00:04:42.670 align:start position:0%\\nat the highest cache level L1 if the\\nrequested<00:04:41.039><c> address</c><00:04:41.320><c> is</c><00:04:41.479><c> found</c><00:04:41.720><c> in</c><00:04:41.880><c> L1</c><00:04:42.520><c> the</c>\\n\\n00:04:42.670 --> 00:04:42.680 align:start position:0%\\nrequested address is found in L1 the\\n \\n\\n00:04:42.680 --> 00:04:44.310 align:start position:0%\\nrequested address is found in L1 the\\ndata<00:04:42.919><c> is</c><00:04:43.039><c> simply</c><00:04:43.360><c> forwarded</c><00:04:43.960><c> to</c><00:04:44.120><c> the</c>\\n\\n00:04:44.310 --> 00:04:44.320 align:start position:0%\\ndata is simply forwarded to the\\n \\n\\n00:04:44.320 --> 00:04:47.189 align:start position:0%\\ndata is simply forwarded to the\\nprocessor<00:04:45.120><c> core</c><00:04:46.120><c> if</c><00:04:46.280><c> the</c><00:04:46.440><c> address</c><00:04:46.720><c> is</c><00:04:46.880><c> not</c><00:04:47.039><c> in</c>\\n\\n00:04:47.189 --> 00:04:47.199 align:start position:0%\\nprocessor core if the address is not in\\n \\n\\n00:04:47.199 --> 00:04:49.670 align:start position:0%\\nprocessor core if the address is not in\\nL1<00:04:47.880><c> the</c><00:04:48.000><c> search</c><00:04:48.320><c> moves</c><00:04:48.639><c> to</c>\\n\\n00:04:49.670 --> 00:04:49.680 align:start position:0%\\nL1 the search moves to\\n \\n\\n00:04:49.680 --> 00:04:52.790 align:start position:0%\\nL1 the search moves to\\nL2<00:04:50.680><c> if</c><00:04:50.840><c> the</c><00:04:50.960><c> address</c><00:04:51.280><c> is</c><00:04:51.400><c> found</c><00:04:51.680><c> in</c><00:04:51.800><c> L2</c><00:04:52.639><c> the</c>\\n\\n00:04:52.790 --> 00:04:52.800 align:start position:0%\\nL2 if the address is found in L2 the\\n \\n\\n00:04:52.800 --> 00:04:55.670 align:start position:0%\\nL2 if the address is found in L2 the\\ndata<00:04:53.039><c> is</c><00:04:53.199><c> copied</c><00:04:53.680><c> to</c><00:04:53.800><c> L1</c><00:04:54.639><c> and</c><00:04:54.800><c> then</c><00:04:54.960><c> forwarded</c>\\n\\n00:04:55.670 --> 00:04:55.680 align:start position:0%\\ndata is copied to L1 and then forwarded\\n \\n\\n00:04:55.680 --> 00:04:58.189 align:start position:0%\\ndata is copied to L1 and then forwarded\\nto<00:04:55.840><c> the</c><00:04:56.039><c> processor</c><00:04:56.639><c> core</c><00:04:57.639><c> this</c><00:04:57.800><c> step</c><00:04:58.039><c> is</c>\\n\\n00:04:58.189 --> 00:04:58.199 align:start position:0%\\nto the processor core this step is\\n \\n\\n00:04:58.199 --> 00:05:00.670 align:start position:0%\\nto the processor core this step is\\nimportant<00:04:58.960><c> since</c><00:04:59.199><c> having</c><00:04:59.440><c> the</c><00:04:59.759><c> data</c><00:04:59.960><c> in</c><00:05:00.080><c> L1</c>\\n\\n00:05:00.670 --> 00:05:00.680 align:start position:0%\\nimportant since having the data in L1\\n \\n\\n00:05:00.680 --> 00:05:02.390 align:start position:0%\\nimportant since having the data in L1\\nimproves<00:05:01.120><c> the</c><00:05:01.240><c> heat</c><00:05:01.479><c> rate</c><00:05:01.880><c> if</c><00:05:02.039><c> the</c><00:05:02.160><c> same</c>\\n\\n00:05:02.390 --> 00:05:02.400 align:start position:0%\\nimproves the heat rate if the same\\n \\n\\n00:05:02.400 --> 00:05:04.990 align:start position:0%\\nimproves the heat rate if the same\\naddress<00:05:02.680><c> is</c><00:05:02.919><c> accessed</c><00:05:03.360><c> again</c><00:05:03.720><c> soon</c><00:05:04.720><c> if</c><00:05:04.840><c> the</c>\\n\\n00:05:04.990 --> 00:05:05.000 align:start position:0%\\naddress is accessed again soon if the\\n \\n\\n00:05:05.000 --> 00:05:07.270 align:start position:0%\\naddress is accessed again soon if the\\naddress<00:05:05.320><c> is</c><00:05:05.440><c> not</c><00:05:05.639><c> found</c><00:05:05.840><c> in</c><00:05:06.000><c> L2</c><00:05:06.720><c> the</c><00:05:06.840><c> search</c>\\n\\n00:05:07.270 --> 00:05:07.280 align:start position:0%\\naddress is not found in L2 the search\\n \\n\\n00:05:07.280 --> 00:05:10.430 align:start position:0%\\naddress is not found in L2 the search\\ncontinues<00:05:07.759><c> in</c><00:05:07.880><c> the</c><00:05:08.000><c> largest</c><00:05:08.440><c> cache</c><00:05:09.320><c> L3</c><00:05:10.320><c> the</c>\\n\\n00:05:10.430 --> 00:05:10.440 align:start position:0%\\ncontinues in the largest cache L3 the\\n \\n\\n00:05:10.440 --> 00:05:12.749 align:start position:0%\\ncontinues in the largest cache L3 the\\nsame<00:05:10.680><c> idea</c><00:05:10.960><c> applies</c><00:05:11.400><c> here</c><00:05:12.000><c> if</c><00:05:12.160><c> the</c><00:05:12.320><c> address</c><00:05:12.600><c> is</c>\\n\\n00:05:12.749 --> 00:05:12.759 align:start position:0%\\nsame idea applies here if the address is\\n \\n\\n00:05:12.759 --> 00:05:16.629 align:start position:0%\\nsame idea applies here if the address is\\nfound<00:05:13.080><c> in</c><00:05:13.240><c> L3</c><00:05:13.880><c> it</c><00:05:14.000><c> is</c><00:05:14.199><c> copied</c><00:05:14.600><c> to</c><00:05:14.759><c> L2</c><00:05:15.560><c> then</c><00:05:15.800><c> L1</c>\\n\\n00:05:16.629 --> 00:05:16.639 align:start position:0%\\nfound in L3 it is copied to L2 then L1\\n \\n\\n00:05:16.639 --> 00:05:18.909 align:start position:0%\\nfound in L3 it is copied to L2 then L1\\nand<00:05:16.880><c> finally</c><00:05:17.360><c> forwarded</c><00:05:17.960><c> to</c><00:05:18.080><c> the</c><00:05:18.240><c> processor</c>\\n\\n00:05:18.909 --> 00:05:18.919 align:start position:0%\\nand finally forwarded to the processor\\n \\n\\n00:05:18.919 --> 00:05:21.390 align:start position:0%\\nand finally forwarded to the processor\\ncore<00:05:19.919><c> if</c><00:05:20.039><c> none</c><00:05:20.240><c> of</c><00:05:20.360><c> the</c><00:05:20.479><c> caches</c><00:05:20.880><c> contain</c><00:05:21.240><c> the</c>\\n\\n00:05:21.390 --> 00:05:21.400 align:start position:0%\\ncore if none of the caches contain the\\n \\n\\n00:05:21.400 --> 00:05:24.029 align:start position:0%\\ncore if none of the caches contain the\\naddress<00:05:22.039><c> the</c><00:05:22.160><c> read</c><00:05:22.520><c> request</c><00:05:23.120><c> is</c><00:05:23.240><c> sent</c><00:05:23.680><c> to</c><00:05:23.840><c> main</c>\\n\\n00:05:24.029 --> 00:05:24.039 align:start position:0%\\naddress the read request is sent to main\\n \\n\\n00:05:24.039 --> 00:05:26.309 align:start position:0%\\naddress the read request is sent to main\\nmemory<00:05:24.840><c> the</c><00:05:25.039><c> data</c><00:05:25.280><c> from</c><00:05:25.479><c> Main</c><00:05:25.680><c> memory</c><00:05:26.120><c> is</c>\\n\\n00:05:26.309 --> 00:05:26.319 align:start position:0%\\nmemory the data from Main memory is\\n \\n\\n00:05:26.319 --> 00:05:28.309 align:start position:0%\\nmemory the data from Main memory is\\nretrieved<00:05:27.000><c> and</c><00:05:27.199><c> in</c><00:05:27.360><c> this</c><00:05:27.479><c> fully</c><00:05:27.759><c> inclusive</c>\\n\\n00:05:28.309 --> 00:05:28.319 align:start position:0%\\nretrieved and in this fully inclusive\\n \\n\\n00:05:28.319 --> 00:05:32.270 align:start position:0%\\nretrieved and in this fully inclusive\\nsystem<00:05:28.919><c> it</c><00:05:29.039><c> is</c><00:05:29.199><c> copied</c><00:05:29.720><c> to</c><00:05:29.840><c> L3</c><00:05:30.560><c> L2</c><00:05:31.319><c> and</c><00:05:31.520><c> L1</c>\\n\\n00:05:32.270 --> 00:05:32.280 align:start position:0%\\nsystem it is copied to L3 L2 and L1\\n \\n\\n00:05:32.280 --> 00:05:34.790 align:start position:0%\\nsystem it is copied to L3 L2 and L1\\nbefore<00:05:32.600><c> being</c><00:05:32.840><c> forwarded</c><00:05:33.360><c> to</c><00:05:33.479><c> the</c><00:05:33.680><c> processor</c>\\n\\n00:05:34.790 --> 00:05:34.800 align:start position:0%\\nbefore being forwarded to the processor\\n \\n\\n00:05:34.800 --> 00:05:38.029 align:start position:0%\\nbefore being forwarded to the processor\\ncore<00:05:35.800><c> when</c><00:05:35.960><c> the</c><00:05:36.080><c> CPU</c><00:05:36.479><c> issues</c><00:05:36.759><c> a</c><00:05:36.919><c> right</c><00:05:37.199><c> request</c>\\n\\n00:05:38.029 --> 00:05:38.039 align:start position:0%\\ncore when the CPU issues a right request\\n \\n\\n00:05:38.039 --> 00:05:39.830 align:start position:0%\\ncore when the CPU issues a right request\\nhow<00:05:38.199><c> the</c><00:05:38.360><c> cash</c><00:05:38.639><c> handles</c><00:05:39.000><c> it</c><00:05:39.240><c> depends</c><00:05:39.560><c> on</c><00:05:39.720><c> the</c>\\n\\n00:05:39.830 --> 00:05:39.840 align:start position:0%\\nhow the cash handles it depends on the\\n \\n\\n00:05:39.840 --> 00:05:42.710 align:start position:0%\\nhow the cash handles it depends on the\\nsystem's<00:05:40.280><c> right</c><00:05:40.600><c> policy</c><00:05:41.600><c> for</c><00:05:41.880><c> Simplicity</c>\\n\\n00:05:42.710 --> 00:05:42.720 align:start position:0%\\nsystem's right policy for Simplicity\\n \\n\\n00:05:42.720 --> 00:05:44.510 align:start position:0%\\nsystem's right policy for Simplicity\\nlet's<00:05:42.960><c> assume</c><00:05:43.280><c> all</c><00:05:43.479><c> caches</c><00:05:43.840><c> in</c><00:05:43.960><c> the</c><00:05:44.080><c> hierarchy</c>\\n\\n00:05:44.510 --> 00:05:44.520 align:start position:0%\\nlet's assume all caches in the hierarchy\\n \\n\\n00:05:44.520 --> 00:05:47.189 align:start position:0%\\nlet's assume all caches in the hierarchy\\nuse<00:05:44.800><c> the</c><00:05:44.919><c> same</c><00:05:45.360><c> policy</c><00:05:46.360><c> in</c><00:05:46.479><c> the</c><00:05:46.639><c> right</c><00:05:46.880><c> through</c>\\n\\n00:05:47.189 --> 00:05:47.199 align:start position:0%\\nuse the same policy in the right through\\n \\n\\n00:05:47.199 --> 00:05:49.749 align:start position:0%\\nuse the same policy in the right through\\npolicy<00:05:47.919><c> data</c><00:05:48.199><c> written</c><00:05:48.520><c> to</c><00:05:48.639><c> L1</c><00:05:49.199><c> immediately</c>\\n\\n00:05:49.749 --> 00:05:49.759 align:start position:0%\\npolicy data written to L1 immediately\\n \\n\\n00:05:49.759 --> 00:05:53.670 align:start position:0%\\npolicy data written to L1 immediately\\npropagates<00:05:50.240><c> to</c><00:05:50.400><c> L2</c><00:05:51.160><c> L3</c><00:05:51.919><c> and</c><00:05:52.080><c> Main</c><00:05:52.440><c> memory</c><00:05:53.440><c> this</c>\\n\\n00:05:53.670 --> 00:05:53.680 align:start position:0%\\npropagates to L2 L3 and Main memory this\\n \\n\\n00:05:53.680 --> 00:05:55.510 align:start position:0%\\npropagates to L2 L3 and Main memory this\\nensures<00:05:54.080><c> all</c><00:05:54.240><c> levels</c><00:05:54.720><c> remain</c><00:05:54.919><c> synchronized</c>\\n\\n00:05:55.510 --> 00:05:55.520 align:start position:0%\\nensures all levels remain synchronized\\n \\n\\n00:05:55.520 --> 00:05:57.110 align:start position:0%\\nensures all levels remain synchronized\\nduring<00:05:55.720><c> a</c><00:05:55.919><c> right</c>\\n\\n00:05:57.110 --> 00:05:57.120 align:start position:0%\\nduring a right\\n \\n\\n00:05:57.120 --> 00:05:59.710 align:start position:0%\\nduring a right\\noperation<00:05:58.120><c> in</c><00:05:58.319><c> contrast</c><00:05:58.960><c> the</c><00:05:59.120><c> right</c><00:05:59.319><c> back</c>\\n\\n00:05:59.710 --> 00:05:59.720 align:start position:0%\\noperation in contrast the right back\\n \\n\\n00:05:59.720 --> 00:06:01.950 align:start position:0%\\noperation in contrast the right back\\npolicy<00:06:00.199><c> delays</c><00:06:00.680><c> updates</c><00:06:01.080><c> to</c><00:06:01.240><c> lower</c><00:06:01.520><c> levels</c><00:06:01.800><c> of</c>\\n\\n00:06:01.950 --> 00:06:01.960 align:start position:0%\\npolicy delays updates to lower levels of\\n \\n\\n00:06:01.960 --> 00:06:04.150 align:start position:0%\\npolicy delays updates to lower levels of\\nthe<00:06:02.280><c> hierarchy</c><00:06:03.280><c> if</c><00:06:03.400><c> a</c><00:06:03.560><c> data</c><00:06:03.759><c> block</c><00:06:04.000><c> is</c>\\n\\n00:06:04.150 --> 00:06:04.160 align:start position:0%\\nthe hierarchy if a data block is\\n \\n\\n00:06:04.160 --> 00:06:07.070 align:start position:0%\\nthe hierarchy if a data block is\\nmodified<00:06:04.600><c> in</c><00:06:04.759><c> L1</c><00:06:05.440><c> it</c><00:06:05.560><c> is</c><00:06:05.720><c> marked</c><00:06:06.039><c> as</c><00:06:06.199><c> dirty</c><00:06:06.919><c> the</c>\\n\\n00:06:07.070 --> 00:06:07.080 align:start position:0%\\nmodified in L1 it is marked as dirty the\\n \\n\\n00:06:07.080 --> 00:06:09.390 align:start position:0%\\nmodified in L1 it is marked as dirty the\\nupdate<00:06:07.440><c> to</c><00:06:07.639><c> lower</c><00:06:07.960><c> caches</c><00:06:08.360><c> or</c><00:06:08.560><c> main</c><00:06:08.840><c> memory</c>\\n\\n00:06:09.390 --> 00:06:09.400 align:start position:0%\\nupdate to lower caches or main memory\\n \\n\\n00:06:09.400 --> 00:06:10.990 align:start position:0%\\nupdate to lower caches or main memory\\nonly<00:06:09.680><c> occurs</c><00:06:10.080><c> when</c><00:06:10.240><c> the</c><00:06:10.400><c> data</c><00:06:10.639><c> block</c><00:06:10.880><c> is</c>\\n\\n00:06:10.990 --> 00:06:11.000 align:start position:0%\\nonly occurs when the data block is\\n \\n\\n00:06:11.000 --> 00:06:14.270 align:start position:0%\\nonly occurs when the data block is\\nevicted<00:06:11.400><c> from</c><00:06:11.759><c> L1</c><00:06:12.759><c> for</c><00:06:13.000><c> example</c><00:06:13.639><c> when</c><00:06:13.800><c> a</c><00:06:13.960><c> dirty</c>\\n\\n00:06:14.270 --> 00:06:14.280 align:start position:0%\\nevicted from L1 for example when a dirty\\n \\n\\n00:06:14.280 --> 00:06:16.430 align:start position:0%\\nevicted from L1 for example when a dirty\\nblock<00:06:14.520><c> is</c><00:06:14.680><c> evicted</c><00:06:15.039><c> from</c><00:06:15.199><c> L1</c><00:06:15.880><c> it</c><00:06:16.000><c> is</c><00:06:16.120><c> written</c>\\n\\n00:06:16.430 --> 00:06:16.440 align:start position:0%\\nblock is evicted from L1 it is written\\n \\n\\n00:06:16.440 --> 00:06:18.710 align:start position:0%\\nblock is evicted from L1 it is written\\nto<00:06:16.599><c> L2</c><00:06:17.240><c> where</c><00:06:17.400><c> it</c><00:06:17.520><c> will</c><00:06:17.759><c> also</c><00:06:18.039><c> be</c><00:06:18.160><c> marked</c><00:06:18.520><c> as</c>\\n\\n00:06:18.710 --> 00:06:18.720 align:start position:0%\\nto L2 where it will also be marked as\\n \\n\\n00:06:18.720 --> 00:06:22.230 align:start position:0%\\nto L2 where it will also be marked as\\ndirty<00:06:19.240><c> waiting</c><00:06:19.639><c> eviction</c><00:06:20.160><c> to</c><00:06:20.360><c> the</c><00:06:20.520><c> next</c><00:06:21.240><c> level</c>\\n\\n00:06:22.230 --> 00:06:22.240 align:start position:0%\\ndirty waiting eviction to the next level\\n \\n\\n00:06:22.240 --> 00:06:24.110 align:start position:0%\\ndirty waiting eviction to the next level\\nright<00:06:22.520><c> misses</c><00:06:22.880><c> are</c><00:06:23.080><c> handled</c><00:06:23.639><c> based</c><00:06:23.880><c> on</c><00:06:23.960><c> the</c>\\n\\n00:06:24.110 --> 00:06:24.120 align:start position:0%\\nright misses are handled based on the\\n \\n\\n00:06:24.120 --> 00:06:27.150 align:start position:0%\\nright misses are handled based on the\\nCash's<00:06:24.479><c> allocation</c><00:06:25.160><c> policy</c><00:06:26.120><c> WR</c><00:06:26.440><c> allocate</c>\\n\\n00:06:27.150 --> 00:06:27.160 align:start position:0%\\nCash's allocation policy WR allocate\\n \\n\\n00:06:27.160 --> 00:06:29.189 align:start position:0%\\nCash's allocation policy WR allocate\\nures<00:06:27.720><c> data</c><00:06:27.960><c> blocks</c><00:06:28.280><c> are</c><00:06:28.479><c> brought</c><00:06:28.800><c> into</c><00:06:29.080><c> the</c>\\n\\n00:06:29.189 --> 00:06:29.199 align:start position:0%\\nures data blocks are brought into the\\n \\n\\n00:06:29.199 --> 00:06:31.670 align:start position:0%\\nures data blocks are brought into the\\ncash<00:06:29.599><c> hierarchy</c><00:06:30.039><c> on</c><00:06:30.160><c> a</c><00:06:30.360><c> miss</c><00:06:30.800><c> and</c><00:06:31.039><c> updated</c>\\n\\n00:06:31.670 --> 00:06:31.680 align:start position:0%\\ncash hierarchy on a miss and updated\\n \\n\\n00:06:31.680 --> 00:06:33.870 align:start position:0%\\ncash hierarchy on a miss and updated\\nthere<00:06:32.039><c> while</c><00:06:32.280><c> with</c><00:06:32.440><c> no</c><00:06:32.680><c> right</c><00:06:33.039><c> allocate</c><00:06:33.720><c> the</c>\\n\\n00:06:33.870 --> 00:06:33.880 align:start position:0%\\nthere while with no right allocate the\\n \\n\\n00:06:33.880 --> 00:06:35.990 align:start position:0%\\nthere while with no right allocate the\\ncach<00:06:34.080><c> is</c><00:06:34.280><c> bypassed</c><00:06:35.000><c> and</c><00:06:35.120><c> the</c><00:06:35.280><c> data</c><00:06:35.520><c> is</c><00:06:35.599><c> written</c>\\n\\n00:06:35.990 --> 00:06:36.000 align:start position:0%\\ncach is bypassed and the data is written\\n \\n\\n00:06:36.000 --> 00:06:38.469 align:start position:0%\\ncach is bypassed and the data is written\\ndirectly<00:06:36.360><c> to</c><00:06:36.520><c> the</c><00:06:36.680><c> next</c><00:06:36.919><c> level</c><00:06:37.880><c> if</c><00:06:38.039><c> all</c><00:06:38.240><c> cash</c>\\n\\n00:06:38.469 --> 00:06:38.479 align:start position:0%\\ndirectly to the next level if all cash\\n \\n\\n00:06:38.479 --> 00:06:40.110 align:start position:0%\\ndirectly to the next level if all cash\\nlevels<00:06:38.759><c> are</c><00:06:38.960><c> configured</c><00:06:39.440><c> as</c><00:06:39.599><c> no</c><00:06:39.880><c> right</c>\\n\\n00:06:40.110 --> 00:06:40.120 align:start position:0%\\nlevels are configured as no right\\n \\n\\n00:06:40.120 --> 00:06:42.230 align:start position:0%\\nlevels are configured as no right\\nallocate<00:06:40.960><c> data</c><00:06:41.199><c> is</c><00:06:41.319><c> written</c><00:06:41.680><c> directly</c><00:06:42.080><c> to</c>\\n\\n00:06:42.230 --> 00:06:42.240 align:start position:0%\\nallocate data is written directly to\\n \\n\\n00:06:42.240 --> 00:06:42.990 align:start position:0%\\nallocate data is written directly to\\nmain\\n\\n00:06:42.990 --> 00:06:43.000 align:start position:0%\\nmain\\n \\n\\n00:06:43.000 --> 00:06:45.029 align:start position:0%\\nmain\\nmemory<00:06:44.000><c> I</c><00:06:44.120><c> hope</c><00:06:44.280><c> you</c><00:06:44.360><c> found</c><00:06:44.599><c> this</c><00:06:44.800><c> video</c>\\n\\n00:06:45.029 --> 00:06:45.039 align:start position:0%\\nmemory I hope you found this video\\n \\n\\n00:06:45.039 --> 00:06:47.629 align:start position:0%\\nmemory I hope you found this video\\nhelpful<00:06:45.800><c> if</c><00:06:45.919><c> you</c><00:06:46.080><c> did</c><00:06:46.479><c> click</c><00:06:46.759><c> the</c><00:06:46.919><c> like</c><00:06:47.120><c> button</c>\\n\\n00:06:47.629 --> 00:06:47.639 align:start position:0%\\nhelpful if you did click the like button\\n \\n\\n00:06:47.639 --> 00:06:49.350 align:start position:0%\\nhelpful if you did click the like button\\nand<00:06:47.840><c> subscribe</c><00:06:48.319><c> for</c><00:06:48.479><c> more</c><00:06:48.680><c> videos</c><00:06:49.000><c> like</c><00:06:49.199><c> this</c>\\n\\n00:06:49.350 --> 00:06:49.360 align:start position:0%\\nand subscribe for more videos like this\\n \\n\\n00:06:49.360 --> 00:06:51.230 align:start position:0%\\nand subscribe for more videos like this\\none<00:06:49.880><c> thanks</c><00:06:50.120><c> for</c><00:06:50.319><c> watching</c><00:06:50.759><c> I'll</c><00:06:50.919><c> see</c><00:06:51.120><c> you</c>\\n\\n00:06:51.230 --> 00:06:51.240 align:start position:0%\\none thanks for watching I'll see you\\n \\n\\n00:06:51.240 --> 00:06:54.000 align:start position:0%\\none thanks for watching I'll see you\\nsoon\\n\\n\",\"file_type\":\"Srt\"}}]", "[{\"file_name\":{\"Windows\":[84,104,101,32,65,110,97,116,111,109,121,32,111,102,32,97,32,77,111,100,101,114,110,32,67,80,85,32,67,97,99,104,101,32,72,105,101,114,97,114,99,104,121]},\"contents\":\"did you know that accessing main memory can take hundreds of CPU Cycles the processor operates at a very high speed but every time it needs to fetch data for main memory it's forced to wait until the requested data is retrieved this huge delay is why computers have caches to keep the data the CPU needs closer and minimize those costly interruptions modern CPUs feature a hierarchial cache system where the cache closest to the processor core is the smallest in fastest while the furthest cache is the largest but slowest large caches are inherently more complex which increases their access times so to maximize performance while reducing latency and cost the first level of cache known as L1 is designed to be very small to match the speed of the processor L1 caches are typically divided into two separate components one optimized for data fetching and another for storing instructions at this point the size of the cache becomes a limiting factor so to solve this many CPU architectures incorporate an additional cache that is larger in size but works at lower speeds this is known as L2 cache the L2 cache is usually a unified cache which means it can store both data and instructions it is dedicated to a single processor core and can directly communicate with the L1 caches but most modern systems are multi-core systems and need a fast way to share data between them that's why CPUs usually have another cache L3 this cache is larger but slower than L2 it serves two main purposes it allows data sharing between processor cores without accessing main memory and it provides an additional layer in the memory hierarchy when both L1 and L2 caches miss the L3 cache is checked before resorting to main memory some specialized systems add an L4 cache on top of the usual L1 2 and three caches the L1 cach is the smallest in the hierarchy typically ranging from 16 kiloby to 128 kilobytes per core it has an associativity of between two and eight ways it is the fastest among all caches with a latency in the range of a few CPU Cycles L2 caches are slightly larger than L1 ranging from 256 kiloby to 2 megabytes per core with older machines having up to several megabytes per core in terms of associativity L2 has between four and 16 ways and a latency of 4 to 10 CPU Cycles L3 caches are the largest in the hierarchy in most architectures ranging from 2 mbes to 32 mbes per core with some apple and AMD CPUs having more than 32 MBT per core L3 typically has an associativity of 16 ways though this can vary between system architectures it has the longest latency ranging from 10 10 to 40 Cycles cash hierarchies can be categorized by their inclusion policies which decide whether a data block is stored in just one cach level copied across multiple levels or handled in a manner the three main inclusion policies are inclusive exclusive and non-inclusive non-exclusive or nine in short in the inclusive policy data stored in a higher level cache such as L1 which is close closest to the processor core is also stored in lower level caches like L2 and possibly L3 in this case you could say that L2 includes L1 the exclusive policy states that a data block can only exist in one cach level at a time if it's an L1 it won't be in L2 or L3 and vice versa in this instance L2 is exclusive of L1 the non-inclusive non-exclusive policy is a hybrid of the previous two the there is no strict rule for duplication data may or may not exist across multiple cache levels depending on the systems design in Real World Systems CPU cache hierarchies combine inclusion policies for example Intel processors like sandybridge ivybridge and Skylake have an inclusive L3 cache and a non-inclusive non-exclusive L2 cache each of these policies has its benefits and drawbacks but they all play a role in how data is retrieved or written within the cash hierarchy let's look at an example let's assume we have an inclusive cache hierarchy with three levels a read request will always start at the highest cache level L1 if the requested address is found in L1 the data is simply forwarded to the processor core if the address is not in L1 the search moves to L2 if the address is found in L2 the data is copied to L1 and then forwarded to the processor core this step is important since having the data in L1 improves the heat rate if the same address is accessed again soon if the address is not found in L2 the search continues in the largest cache L3 the same idea applies here if the address is found in L3 it is copied to L2 then L1 and finally forwarded to the processor core if none of the caches contain the address the read request is sent to main memory the data from Main memory is retrieved and in this fully inclusive system it is copied to L3 L2 and L1 before being forwarded to the processor core when the CPU issues a right request how the cash handles it depends on the system's right policy for Simplicity let's assume all caches in the hierarchy use the same policy in the right through policy data written to L1 immediately propagates to L2 L3 and Main memory this ensures all levels remain synchronized during a right operation in contrast the right back policy delays updates to lower levels of the hierarchy if a data block is modified in L1 it is marked as dirty the update to lower caches or main memory only occurs when the data block is evicted from L1 for example when a dirty block is evicted from L1 it is written to L2 where it will also be marked as dirty waiting eviction to the next level right misses are handled based on the Cash's allocation policy WR allocate ures data blocks are brought into the cash hierarchy on a miss and updated there while with no right allocate the cach is bypassed and the data is written directly to the next level if all cash levels are configured as no right allocate data is written directly to main memory I hope you found this video helpful if you did click the like button and subscribe for more videos like this one thanks for watching I'll see you soon\",\"file_type\":\"Text\"}]")]
    fn youtube_transcribe_tests(#[case] ser_file_type: &str, #[case] ser_expected: &str) {
        let input_files: Vec<FileType> = serde_json::from_str(ser_file_type).unwrap();
        let expected: Vec<StringFile> = serde_json::from_str(ser_expected).unwrap();

        let results: Vec<StringFile> = input_files.into_iter().map(|file| transcribe_file(file).expect("transcription should be valid")).collect();
        assert_eq!(results, expected);
    }
}
